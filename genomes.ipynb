{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "d = {\"pop\": 100}\n",
    "# Make dict into args\n",
    "args = argparse.Namespace(**d)\n",
    "args.pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paul/debug_config.json\n",
      "Namespace(env_name='walker2d_uni', episode_length=100, evals=100, seed=42, policy_hidden_layer_sizes=(16, 16), critic_hidden_layer_sizes=(64, 64), num_init_cvt_samples=50000, num_centroids=1024, min_bd=0.0, max_bd=1.0, es='cmaes', pop=10, es_sigma=0.01, sample_mirror=True, sample_rank_norm=True, adam_optimizer=True, learning_rate=0.01, l2_coefficient=0.02, nses_emitter=False, novelty_nearest_neighbors=10, rl=True, testrl=True, carlies=False, elastic_pull=0.001, actor_injection=True, nb_injections=1, critic_training=1000, pg_training=1000, output='debug', plot=False, wandb='', tag='', jobid='', log_period=1, debug=True, num_gens=10, algo='CMAES-RL-TestRL-AI', config='ES 10 - σ 0.01 - α 0.01 - ε 0.001')\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/home/paul/debug\"\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import json\n",
    "\n",
    "# Load config\n",
    "print(save_path + \"_config.json\")\n",
    "with open(save_path + \"_config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    # Lists to tuples\n",
    "    for k, v in config.items():\n",
    "        if isinstance(v, list):\n",
    "            config[k] = tuple(v)\n",
    "    config = argparse.Namespace(**config)\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device count: 1 [GpuDevice(id=0, process_index=0)]\n"
     ]
    }
   ],
   "source": [
    "from qdax.core.rl_es_parts.es_setup import setup_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported modules\n",
      "Doing actor injection x 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/Dev/QDax/qdax/core/rl_es_parts/es_utils.py:253: UserWarning: This type of repertoire does not store the extra scores computed by the scoring function\n",
      "  repertoire = ESRepertoire.init(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_shapes [(16,), (17, 16), (16,), (16, 16), (6,), (16, 6)]\n",
      "sizes [ 16 272  16 256   6  96]\n",
      "Initialized ES\n",
      "<qdax.core.rl_es_parts.mono_cmaes.MonoCMAESEmitter object at 0x7fe13081ea90>\n"
     ]
    }
   ],
   "source": [
    "EM = setup_es(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EM.es,\n",
    "env = EM.env,\n",
    "policy_network = EM.policy_network,\n",
    "emitter = EM.emitter,\n",
    "emitter_state = EM.emitter_state,\n",
    "repertoire = EM.repertoire,\n",
    "random_key = EM.random_key,\n",
    "wandb_run  = EM. wandb_run,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "offspring = jnp.load(save_path + \"offspring.npy\")\n",
    "actor = jnp.load(save_path + \"_actor.npy\")\n",
    "critic = jnp.load(save_path + \"_critic.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(662,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offspring.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'action_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mflatten_util\u001b[39;00m \u001b[39mimport\u001b[39;00m ravel_pytree\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mqdax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mneuroevolution\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnetworks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnetworks\u001b[39;00m \u001b[39mimport\u001b[39;00m MLP\n\u001b[0;32m----> 7\u001b[0m policy_layer_sizes \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mpolicy_hidden_layer_sizes \u001b[39m+\u001b[39m (env\u001b[39m.\u001b[39;49maction_size,)\n\u001b[1;32m      8\u001b[0m policy_network \u001b[39m=\u001b[39m MLP(\n\u001b[1;32m      9\u001b[0m     layer_sizes\u001b[39m=\u001b[39mpolicy_layer_sizes,\n\u001b[1;32m     10\u001b[0m     kernel_init\u001b[39m=\u001b[39mjax\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39minitializers\u001b[39m.\u001b[39mlecun_uniform(),\n\u001b[1;32m     11\u001b[0m     final_activation\u001b[39m=\u001b[39mjnp\u001b[39m.\u001b[39mtanh,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     15\u001b[0m random_key \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mPRNGKey(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'action_size'"
     ]
    }
   ],
   "source": [
    "import jax \n",
    "from qdax import environments\n",
    "from jax.flatten_util import ravel_pytree\n",
    "\n",
    "from qdax.core.neuroevolution.networks.networks import MLP\n",
    "\n",
    "policy_layer_sizes = config.policy_hidden_layer_sizes + (env.action_size,)\n",
    "policy_network = MLP(\n",
    "    layer_sizes=policy_layer_sizes,\n",
    "    kernel_init=jax.nn.initializers.lecun_uniform(),\n",
    "    final_activation=jnp.tanh,\n",
    ")\n",
    "\n",
    "\n",
    "random_key = jax.random.PRNGKey(0)\n",
    "keys = jax.random.split(random_key, num=1)\n",
    "\n",
    "env = environments.create(config.env_name, episode_length=config.episode_length)\n",
    "\n",
    "fake_batch = jnp.zeros(shape=(1, env.observation_size))\n",
    "init_variables = jax.vmap(policy_network.init)(keys, fake_batch)\n",
    "\n",
    "_, reconstruction_fn = ravel_pytree(init_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_fn(actor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qdax_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
